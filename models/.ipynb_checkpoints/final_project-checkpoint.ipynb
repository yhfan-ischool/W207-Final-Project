{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W207 Final Project\n",
    "### Kaggle Competition\n",
    "[San Francisco Crime Statistics](https://www.kaggle.com/c/sf-crime)\n",
    "  \n",
    "###  Team Members\n",
    "Chuck Bolin, Matthew Burke, Yun-Hui Fan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# General libraries.\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn import utils\n",
    "\n",
    "# SK-learn libraries for feature extraction from text.\n",
    "from sklearn.feature_extraction.text import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading\n",
    "Load in training and test data to variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_all = pd.read_csv('../data/train.csv', delimiter=',', parse_dates=['Dates'])\n",
    "# test_final contains data which will be submitted to kaggle after predicting categories\n",
    "# Includes ID field not found in training data\n",
    "# Does not include description, category or resolution fields in training data\n",
    "test_final = pd.read_csv('../data/test.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create columns for Year, Month, Day, Day of Week and Hour from `Dates` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check that data has been formed correctly:\n",
      "\n",
      "Training data shape:  (588292, 12)\n",
      "Training labels shape:  588292\n",
      "Test data shape:  (289757, 12)\n",
      "Test labels shape:  289757\n",
      "\n",
      "Top 5 rows of training data:\n",
      "\n",
      "                Dates        Category                      Descript  \\\n",
      "0 2015-05-13 23:53:00        WARRANTS                WARRANT ARREST   \n",
      "1 2015-05-13 23:53:00  OTHER OFFENSES      TRAFFIC VIOLATION ARREST   \n",
      "2 2015-05-13 23:33:00  OTHER OFFENSES      TRAFFIC VIOLATION ARREST   \n",
      "3 2015-05-13 23:30:00   LARCENY/THEFT  GRAND THEFT FROM LOCKED AUTO   \n",
      "4 2015-05-13 23:30:00   LARCENY/THEFT  GRAND THEFT FROM LOCKED AUTO   \n",
      "\n",
      "   DayOfWeek PdDistrict      Resolution                    Address  \\\n",
      "0  Wednesday   NORTHERN  ARREST, BOOKED         OAK ST / LAGUNA ST   \n",
      "1  Wednesday   NORTHERN  ARREST, BOOKED         OAK ST / LAGUNA ST   \n",
      "2  Wednesday   NORTHERN  ARREST, BOOKED  VANNESS AV / GREENWICH ST   \n",
      "3  Wednesday   NORTHERN            NONE   1500 Block of LOMBARD ST   \n",
      "4  Wednesday       PARK            NONE  100 Block of BRODERICK ST   \n",
      "\n",
      "            X          Y  Year  Month  Day  Hour  \n",
      "0 -122.425892  37.774599  2015      5   13    23  \n",
      "1 -122.425892  37.774599  2015      5   13    23  \n",
      "2 -122.424363  37.800414  2015      5   13    23  \n",
      "3 -122.426995  37.800873  2015      5   13    23  \n",
      "4 -122.438738  37.771541  2015      5   13    23  \n"
     ]
    }
   ],
   "source": [
    "def dateAttributes(df):\n",
    "    df = df.copy()\n",
    "    df['Year'] = pd.DatetimeIndex(df['Dates']).year\n",
    "    df['Month'] = pd.DatetimeIndex(df['Dates']).month\n",
    "    df['Day'] = pd.DatetimeIndex(df['Dates']).day\n",
    "    df['Hour'] = pd.DatetimeIndex(df['Dates']).hour\n",
    "    return df\n",
    "\n",
    "train_all = dateAttributes(train_all)\n",
    "\n",
    "# Get all labels\n",
    "labels_all = np.array(train_all[\"Category\"])\n",
    "\n",
    "# Get all data\n",
    "train_data_all = np.array(train_all.drop(['Category'], axis=1))\n",
    "\n",
    "# Define fraction of data to be used as test data\n",
    "fraction = 0.33\n",
    "\n",
    "# Split data into training and test data/labels randomly according to fraction specified\n",
    "train_labels, test_labels, train_data, test_data = train_test_split(labels_all, train_data_all, test_size=fraction)\n",
    "\n",
    "print 'Check that data has been formed correctly:\\n'\n",
    "\n",
    "print 'Training data shape: ', train_data.shape\n",
    "print 'Training labels shape: ', len(train_labels)#train_labels.shape\n",
    "\n",
    "print 'Test data shape: ', test_data.shape\n",
    "print 'Test labels shape: ', len(test_labels)#test_labels.shape\n",
    "\n",
    "print '\\nTop 5 rows of training data:\\n'\n",
    "\n",
    "print train_all.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Do\n",
    "### Feature Engineering\n",
    "* Resolution feature extraction\n",
    "* Description feature extraction\n",
    "* Address / X Y coordinate mapping to more specific locations than neighborhoods?\n",
    "    - round to values (determine precision)\n",
    "    - create XY as single string column\n",
    "    - map to features\n",
    "* Types of crimes from category (violent, non-violent)\n",
    "\n",
    "\n",
    "### Model Selection\n",
    "Test with models that can support predict_proba to predict probability of all categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "### RandomForest Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper function to vectorizer text columns and create new data/vocabulary for training\n",
    "# Maybe make it so it trains and produces predictions/accuracy as well?\n",
    "\n",
    "# Make second function to do parameter optimization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2009 1 25 17]\n"
     ]
    }
   ],
   "source": [
    "cols = (8, 9, 10, 11)\n",
    "print dev_data[0,cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training\n",
      "Completed training\n",
      "Begin prediction\n",
      "Completed prediction\n",
      "\n",
      "Log score: "
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: LARCENY/THEFT",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-7fd13923a675>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'Completed prediction\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0;34m'Log score: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_test_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'Predictions: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/metrics/classification.pyc\u001b[0m in \u001b[0;36mlog_loss\u001b[0;34m(y_true, y_pred, eps, normalize, sample_weight, labels)\u001b[0m\n\u001b[1;32m   1606\u001b[0m     \u001b[0mThe\u001b[0m \u001b[0mlogarithm\u001b[0m \u001b[0mused\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mnatural\u001b[0m \u001b[0mlogarithm\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m     \"\"\"\n\u001b[0;32m-> 1608\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1609\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    380\u001b[0m                                       force_all_finite)\n\u001b[1;32m    381\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: LARCENY/THEFT"
     ]
    }
   ],
   "source": [
    "# Columns to use in baseline classification\n",
    "\n",
    "dev_data = train_data[0:100,]\n",
    "dev_labels = train_labels[0:100]\n",
    "\n",
    "dev_test_data = test_data[0:100,]\n",
    "dev_test_labels = test_labels[0:100]\n",
    "\n",
    "#vocab = CountVectorizer().fit(dev_test_labels).get_feature_names()\n",
    "\n",
    "#dev_labels_vec = CountVectorizer(vocabulary=vocab).fit_transform(dev_labels).toarray()\n",
    "#dev_test_labels_vec = CountVectorizer(vocabulary=vocab).fit_transform(dev_test_labels).toarray()\n",
    "\n",
    "\n",
    "#dev_labels_num = [None]*len(dev_labels_vec)\n",
    "#dev_test_labels_num = [None]*len(dev_test_labels_vec)\n",
    "\n",
    "#for i in range(0,len(cats)):\n",
    "#    dev_labels_num[i] = np.nonzero(dev_labels_vec[i,])[0][0]\n",
    "#    dev_test_labels_num[i] = np.nonzero(dev_test_labels_vec[i,])[0]\n",
    "\n",
    "\n",
    "# Super basic model using only premade numeric columns\n",
    "# i.e. year, month, hour, day\n",
    "cols = (8, 9, 10, 11)\n",
    "\n",
    "rfcl = RandomForestClassifier(n_estimators=100)\n",
    "print 'Begin training'\n",
    "rfcl.fit(dev_data[:,cols], dev_labels)\n",
    "print 'Completed training'\n",
    "\n",
    "print 'Begin prediction'\n",
    "pred_probs = rfcl.predict_proba(dev_test_data[:,cols])\n",
    "pred = rfcl.predict(dev_test_data[:,cols])\n",
    "#rfcl.predict_proba(dftest), index=dftest.index, columns=rfcl.classes_)\n",
    "\n",
    "print 'Completed prediction\\n'\n",
    "\n",
    "print 'Log score: ', metrics.log_loss(pred, dev_test_labels), '\\n'\n",
    "\n",
    "print 'Predictions: ', pred[0]\n",
    "print 'Prediction probabilities: ', pred_probs[0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training\n",
      "Completed training\n",
      "Begin prediction\n",
      "Completed prediction\n",
      "\n",
      "Log score:  1.48748568846 \n",
      "\n",
      "Predictions:  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.]\n",
      "Prediction probabilities:  [[ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " ..., \n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "rfcl = RandomForestClassifier(n_estimators=100)\n",
    "print 'Begin training'\n",
    "rfcl.fit(train_data[:,cols], train_labels)\n",
    "print 'Completed training'\n",
    "\n",
    "print 'Begin prediction'\n",
    "pred_probs = rfcl.predict_proba(test_data[:,cols])\n",
    "pred = rfcl.predict(test_data[:,cols])\n",
    "#rfcl.predict_proba(dftest), index=dftest.index, columns=rfcl.classes_)\n",
    "\n",
    "print 'Completed prediction\\n'\n",
    "\n",
    "print 'Log score: ', metrics.log_loss(pred, test_labels), '\\n'\n",
    "\n",
    "print 'Predictions: ', pred[0]\n",
    "print 'Prediction probabilities: ', pred_probs[0]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
