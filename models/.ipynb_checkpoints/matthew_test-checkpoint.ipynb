{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W207 Final Project\n",
    "### Kaggle Competition\n",
    "[San Francisco Crime Statistics](https://www.kaggle.com/c/sf-crime)\n",
    "  \n",
    "###  Team Members\n",
    "Chuck Bolin, Matthew Burke, Yun-Hui Fan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# General libraries.\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn import utils\n",
    "\n",
    "# SK-learn libraries for feature extraction from text.\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading\n",
    "Load in training and test data to variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_all = pd.read_csv('../data/train.csv', delimiter=',', parse_dates=['Dates'])\n",
    "# test_final contains data which will be submitted to kaggle after predicting categories\n",
    "# Includes ID field not found in training data\n",
    "# Does not include description, category or resolution fields in training data\n",
    "test_final = pd.read_csv('../data/test.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create columns for Year, Month, Day, Day of Week and Hour from `Dates` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check that data has been formed correctly:\n",
      "\n",
      "Training data shape:  (588292, 65)\n",
      "Training labels shape:  588292\n",
      "Test data shape:  (289757, 65)\n",
      "Test labels shape:  289757\n",
      "\n",
      "Top row of training data:\n",
      "\n",
      "['VIOLATION OF MUNICIPAL POLICE CODE' 'Monday' 'TENDERLOIN' 'ARREST, CITED'\n",
      " 'JONES ST / GOLDEN GATE AV' -122.412224164736 37.7820729312029 2008 12 8 6\n",
      " 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0]\n"
     ]
    }
   ],
   "source": [
    "def dateAttributes(df):\n",
    "    df = df.copy()\n",
    "    df['Year'] = pd.DatetimeIndex(df['Dates']).year\n",
    "    df['Month'] = pd.DatetimeIndex(df['Dates']).month\n",
    "    df['Day'] = pd.DatetimeIndex(df['Dates']).day\n",
    "    df['Hour'] = pd.DatetimeIndex(df['Dates']).hour\n",
    "    return df\n",
    "\n",
    "# Extract elements of dates\n",
    "train_all = dateAttributes(train_all)\n",
    "\n",
    "\n",
    "# Column names to binarize:\n",
    "bin_cols = ['Year', 'Month', 'Hour', 'DayOfWeek', 'PdDistrict']\n",
    "\n",
    "# Binarize columns identified above and add to dataframe\n",
    "for column in bin_cols:\n",
    "    dummies = pd.get_dummies(train_all[column])\n",
    "    train_all[dummies.columns] = dummies\n",
    "\n",
    "# Encode all categories into integers\n",
    "encoder = LabelEncoder()\n",
    "labels_all = encoder.fit_transform(train_all['Category'])\n",
    "\n",
    "#Extract categories names from encoder for adding back into final output csv file\n",
    "categories = encoder.classes_\n",
    "\n",
    "# Get all data\n",
    "train_data_all = np.array(train_all.drop(['Category', 'Dates'], axis=1))\n",
    "\n",
    "# Define fraction of data to be used as test data\n",
    "fraction = 0.33\n",
    "\n",
    "# Split data into training and test data/labels randomly according to fraction specified\n",
    "train_labels, test_labels, train_data, test_data = train_test_split(labels_all, train_data_all, test_size=fraction)\n",
    "\n",
    "\n",
    "print 'Check that data has been formed correctly:\\n'\n",
    "\n",
    "print 'Training data shape: ', train_data.shape\n",
    "print 'Training labels shape: ', len(train_labels)#train_labels.shape\n",
    "\n",
    "print 'Test data shape: ', test_data.shape\n",
    "print 'Test labels shape: ', len(test_labels)#test_labels.shape\n",
    "\n",
    "print '\\nTop row of training data:\\n'\n",
    "\n",
    "print train_data [0,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([  u'Descript',  u'DayOfWeek', u'PdDistrict', u'Resolution',\n",
      "          u'Address',          u'X',          u'Y',       u'Year',\n",
      "            u'Month',        u'Day',       u'Hour',          2003,\n",
      "                2004,          2005,          2006,          2007,\n",
      "                2008,          2009,          2010,          2011,\n",
      "                2012,          2013,          2014,          2015,\n",
      "                   1,             2,             3,             4,\n",
      "                   5,             6,             7,             8,\n",
      "                   9,            10,            11,            12,\n",
      "                   0,            13,            14,            15,\n",
      "                  16,            17,            18,            19,\n",
      "                  20,            21,            22,            23,\n",
      "           u'Friday',     u'Monday',   u'Saturday',     u'Sunday',\n",
      "         u'Thursday',    u'Tuesday',  u'Wednesday',    u'BAYVIEW',\n",
      "          u'CENTRAL',  u'INGLESIDE',    u'MISSION',   u'NORTHERN',\n",
      "             u'PARK',   u'RICHMOND',   u'SOUTHERN',    u'TARAVAL',\n",
      "       u'TENDERLOIN'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "colNames = train_all.columns[2:]\n",
    "print colNames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Do\n",
    "### Feature Engineering\n",
    "* Resolution feature extraction\n",
    "* Description feature extraction\n",
    "* Address / X Y coordinate mapping to more specific locations than neighborhoods?\n",
    "    - round to values (determine precision)\n",
    "    - create XY as single string column\n",
    "    - map to features\n",
    "* Types of crimes from category (violent, non-violent)\n",
    "\n",
    "\n",
    "### Model Selection\n",
    "Test with models that can support predict_proba to predict probability of all categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "### RandomForest Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper function to vectorizer text columns and create new data/vocabulary for training\n",
    "# Maybe make it so it trains and produces predictions/accuracy as well?\n",
    "\n",
    "# Make second function to do parameter optimization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training\n",
      "Completed training\n",
      "Begin prediction\n",
      "Completed prediction\n",
      "\n",
      "Log score:  2.63675968946 \n",
      "\n",
      "Probability prediction examples:  [ 0.00226787  0.06127294  0.00037161  0.00049842  0.07778822  0.00438893\n",
      "  0.00261177  0.02516851  0.00057556  0.00102489  0.00221792  0.00039629\n",
      "  0.01265475  0.01571769  0.00079513  0.00142895  0.22935539  0.00225922\n",
      "  0.00089186  0.00910377  0.1185118   0.13201473  0.00088252  0.00258155\n",
      "  0.01032715  0.00430221  0.01273573  0.00558163  0.00053202  0.00286842\n",
      "  0.00064252  0.01896952  0.01009124  0.08776793  0.11717216  0.02110211\n",
      "  0.00312706]\n"
     ]
    }
   ],
   "source": [
    "# Columns to use in baseline classification\n",
    "cols = range(11, len(colNames))\n",
    "\n",
    "dev_data = train_data[0:10000,]\n",
    "dev_labels = train_labels[0:10000]\n",
    "\n",
    "dev_test_data = test_data[0:10000,]\n",
    "dev_test_labels = test_labels[0:10000]\n",
    "\n",
    "lgr = LogisticRegression()\n",
    "print 'Begin training'\n",
    "lgr.fit(dev_data[:,cols], dev_labels)\n",
    "print 'Completed training'\n",
    "\n",
    "print 'Begin prediction'\n",
    "pred_probs = lgr.predict_proba(dev_test_data[:,cols])\n",
    "\n",
    "print 'Completed prediction\\n'\n",
    "\n",
    "print 'Log score: ', metrics.log_loss(dev_test_labels, pred_probs), '\\n'\n",
    "\n",
    "print 'Probability prediction examples: ', pred_probs[0,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_final = dateAttributes(test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting  Year\n",
      "Finished  Year\n",
      "Starting  Month\n",
      "Finished  Month\n",
      "Starting  Hour\n",
      "Finished  Hour\n",
      "Starting  DayOfWeek\n",
      "Finished  DayOfWeek\n",
      "Starting  PdDistrict\n",
      "Finished  PdDistrict\n"
     ]
    }
   ],
   "source": [
    "# Column names to binarize:\n",
    "bin_cols = ['Year', 'Month', 'Hour', 'DayOfWeek', 'PdDistrict']\n",
    "\n",
    "# Binarize columns identified above and add to dataframe\n",
    "for column in bin_cols:\n",
    "    print 'Starting ', column\n",
    "    dummies = pd.get_dummies(test_final[column])\n",
    "    test_final[dummies.columns] = dummies\n",
    "    print 'Finished ', column\n",
    "\n",
    "ids = test_final['Id']\n",
    "\n",
    "test_final_data = np.array(test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0\n",
      " 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0]\n"
     ]
    }
   ],
   "source": [
    "print test_final_data[0,range(12,len(test_final.columns))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training\n",
      "Completed training\n"
     ]
    }
   ],
   "source": [
    "lgrFinal = LogisticRegression()\n",
    "\n",
    "print 'Beginning training'\n",
    "lgrFinal.fit(train_data_all[:,cols], labels_all)\n",
    "print 'Completed training'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin prediction\n",
      "Completed training\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-999a565bfb87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'Completed training'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'Output example:'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cat' is not defined"
     ]
    }
   ],
   "source": [
    "print 'Begin prediction'\n",
    "pred_probs = lgrFinal.predict_proba(test_final_data[:,range(11,len(test_final.columns))])\n",
    "print 'Completed prediction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output to file:  ../data/matthew_submission.csv\n",
      "File creation complete\n"
     ]
    }
   ],
   "source": [
    "output = pd.DataFrame(pred_probs, columns=categories)\n",
    "file_name = '../data/matthew_submission.csv'\n",
    "print 'Output to file: ', file_name\n",
    "output.to_csv(file_name, index=True, index_label='Id')\n",
    "print 'File creation complete'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(884262, 39)\n"
     ]
    }
   ],
   "source": [
    "print output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
